# TIPSY-BOTğŸ¥‚


A fully autonomous Claude-powered software agent that can chat with users, take drink orders, run bar operations, manage inventory, log analytics, and simulate a complete bar business. Built as a testbed for autonomous AI, tool use, business orchestration, and AI safety research.

> "A bartender that remembers your favorite drink, charges your tab, restocks itself, and runs weekly revenue reportsâ€”all autonomously."

---

## ğŸ§  Agent Orchestration & Tools

This system uses a language model (Claude or GPT) as the central **reasoning agent** that communicates with users and coordinates bar operations via external tools.

### ğŸ’¬ LLM Agent
- Claude (via Anthropic API) or GPT-4o
- Reasoning, tool-calling, and dialog
- Initialized using LangChain with ReAct or Function Agent

### ğŸ”§ Tools Connected to the Agent
| Tool         | Purpose                               |
|--------------|----------------------------------------|
| `MakeDrink`  | Sends a drink-making command to an n8n webhook |
| `LogOrder`   | Records the drink order in Supabase    |
| (Future)     | Inventory manager, Stripe payments, Instagram poster, weekly report writer |

### ğŸ§© Architecture Summary

```text
User
 â†“
Claude Agent (LangChain)
 â†“
[MakeDrink]  â†’ n8n workflow (drink prep)
[LogOrder]   â†’ Supabase DB
(More Tools) â†’ APIs for finance, marketing, restock, memory, etc.

```

## ğŸ” AI Safety Research Purpose

This project is a practical sandbox to test and research:

ğŸ§  AI Alignment
	â€¢	Can an open-ended agent understand and respect customer intent?
	â€¢	Can it interpret vague or conflicting commands responsibly?

ğŸ§ª Robustness
	â€¢	How does the system respond to edge cases (e.g., inappropriate requests, inventory errors, drink confusion)?
	â€¢	Can the agent recover from tool failures autonomously?

ğŸ” Long-Term Autonomy
	â€¢	Tests real-world autonomous behavior over multi-day operational loops (ordering, reporting, interacting with humans)
	â€¢	Traces reward hacking, hallucinations, or misaligned subgoals

ğŸ§‘â€ğŸ¤â€ğŸ§‘ Human-AI Interaction (HRI)
	â€¢	Safety under dynamic social pressure (e.g., â€œOne more drink!â€ or â€œGive it for freeâ€)
	â€¢	Intervention logic to enforce boundaries or legal compliance
